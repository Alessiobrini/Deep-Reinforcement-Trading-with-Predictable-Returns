############################## EXPLORATION ##############################
epsilon : 1  # greedy policy choice
steps_to_min_eps : 250000 # decay for the epsilon parameter 0.1 linearly lead to 0.1n after 10 iter. 
min_eps : 0.1 # minimum possible value for epsilon
stddev_noise : 0.2 
theta : 0.15
############################## PER BUFFER ##############################
use_PER : False
PER_e : 0.01  # Hyperparameter that we use to avoid some experiences to have 0 probability of being taken
PER_a : 0.4  # Hyperparameter that we use to make a tradeoff between taking only exp with high priority and sampling randomly
PER_b : 0.6   # importance-sampling, from initial value increasing to 1
PER_b_anneal : True
final_PER_b : 1.0
PER_b_steps : 750000
PER_a_anneal : False
final_PER_a : 1.0
PER_a_steps : 750000
# RL RELATED
DQN_type : 'DDQN'
gamma : 0.7 # discounting factor for the Q target (sort of interest rate)
kappa : 0.0001 # risk aversion
max_experiences : 500000
min_experiences : 5000
copy_step : 1
update_target : 'soft'
tau : 0.001
KLM :  [50000,10000,200000]# [200000,40000,2000000]  # list with actions that each trade can take: from -K to +K lot sizes minimum size of tradable (equities/contracts) and discretization of holding for TabQ (-M,M) holding
RT : [800, 0.0001] # boundaries for returns and ticksize to define the discrete space of returns (only for TabQ)
tablr: 0.001 # learning rate for updating q table
############################## DDPG RELATED ###################################
action_limit : 150000
############################## DL RELATED ##############################
selected_loss: 'huber'
activation : 'relu'
kernel_initializer : 'he_uniform'
optimizer_name : 'adam'
optimizer_decay :  0.0
beta_1: 0.9
beta_2: 0.999
eps_opt: 0.0000001
hidden_units : [128,64]
batch_size : 256
learning_rate_Q : 0.001
learning_rate_p : 0.0001
lr_schedule : 'exponential'
exp_decay_steps : 100000
final_lr : 0.0001
# REGULARIZATION
batch_norm_input : True # bool to decide if add batch norm to input layer or not
batch_norm_hidden : False
mom_batch_norm : 0.99
trainable_batch_norm : True
clipgrad : ''
clipnorm : 1.0
clipvalue : 1.0
clipglob_steps: 50000
############################### PRE TRAINING PARAMETERS ##############################
do_pretrain: False
N_pretrain : 200000
lrate_schedule_pretrain : None
save_ckpt_pretrained_model : 4
############################### DATA SIMULATIONS PARAMETERS ##############################
HalfLife : [2.4, 206, 700] # ,[10,206],[2.5,125,500]]  # half-life of mean reversion to compute speed of mean reversion for the 3 factors
f0 : [0,0,0] #,[0,0],[0,0,0]] #0 #[0,0,0] # initial values for simulating factors
f_param : [0.0114, 0.0231, -0.0225] #,[0.0114, 0.0231, -0.04250],[0.01, 0.0231, -0.04250]] #0.01 #[0.01, 0.0231, -0.04250] # regression parameters for factors [10.32,122.34,-205.59]
sigma  : 0.01 # return volatility
sigmaf : [0.2, 0.1, 0.05] #,[0.4,0.2],[0.1,0.05, 0.025]] # factors volatility
CostMultiplier: 0.01 # Cost multiplier to make the cost proportional to the risk as in Gar Ped (2013)
                          # It is chosen as the median across the estimate of CM for each asset
discount_rate: 0.02 # discount rate as in the paper
Startholding: 0.0
############################### LAUNCH SIMULATIONS ##############################
start_train : 100
seed : 242 # Seed for experiment reproducibility 
N_train : 1000  # training steps (each step consists of one action-value update)
out_of_sample_test : True
N_test: 10000
plot_inputs : 0 # boolean for plotting generated ret and factors
executeDRL: 1 # boolean to decide if run DRL agent
executeRL: 1 # boolean to decide if run RL agent
executeGP: 1 # boolean to decide if run GP solution
executeMV: 1 # boolean to decide if run MV solution
save_results: 1 # boolean to decide if save dataframe of results
save_table: 1
plot_hist: 1 # boolean to decide if plot weight histogram distribution (reduce size of tb logs)
plot_steps_hist : 20000
plot_steps: 1000 # steps for diagnostics on tensorboard
pdist_steps: 5000
save_model: 1 # save trained tf model
save_ckpt_model: 4
saveresultsNBs: 0
use_GPU : False
############################### FOLDER PARAMETERS ##############################
runtype: 'multi' # single, parallel, multiparallel
# Parameter for storing results
outputDir: 'outputs'
outputClass: 'testDDPG'
outputModel: 'test27' # choose model name as number of factors + varying parameter
varying_pars :  # choose a parameter to vary while performing several different experiment
 # leave blank if you don't want to vary any parameter (no subfolder will be created) #['HalfLife','f0', 'f_param', 'sigmaf']
varying_type : 'combination'

